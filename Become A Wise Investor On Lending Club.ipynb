{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Become A Wise Investor on Lending Club\n",
    "\n",
    "LendingClub is a US peer-to-peer lending company, headquartered in San Francisco, California. It was the first peer-to-peer lender to register its offerings as securities with the Securities and Exchange Commission (SEC), and to offer loan trading on a secondary market. LendingClub is the world's largest peer-to-peer lending platform.\n",
    "\n",
    "Given historical data on loans given out with information on whether or not the borrower defaulted (charge-off), I will build a model that can predict wether or nor a borrower will pay back their loan. This way in the future when there is a new potential customer I can assess whether or not they are likely to pay back the loan. The datset can be obtained from [Kaggle](https://www.kaggle.com/wordsforthewise/lending-club)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Duc Cao\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('accepted_2007_to_2018Q4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove redundant and leak information\n",
    "df.drop([\"desc\",\"url\",\"id\",\"member_id\",\"funded_amnt\",\"funded_amnt_inv\",\n",
    "         \"grade\",\"sub_grade\",\"emp_title\",\"issue_d\", \"zip_code\", \"out_prncp\", \n",
    "         \"out_prncp_inv\", \"total_pymnt\", \"total_pymnt_inv\", \"total_rec_prncp\",\n",
    "         \"total_rec_int\", \"total_rec_late_fee\", \"recoveries\", \n",
    "         \"collection_recovery_fee\", \"last_pymnt_d\", \"last_pymnt_amnt\"],\n",
    "          inplace=True,axis=1)\n",
    "# Remove columns with more than 50% missing values\n",
    "df.dropna(axis=1,thresh=df.shape[0]*0.5,inplace=True)\n",
    "\n",
    "# Select features and labels\n",
    "features_labels=['loan_amnt', 'term', 'int_rate', 'installment', 'emp_length',\n",
    "       'home_ownership', 'annual_inc', 'verification_status','loan_status',\n",
    "       'pymnt_plan', 'purpose', 'title', 'addr_state', 'dti', 'delinq_2yrs',\n",
    "       'earliest_cr_line', 'inq_last_6mths', 'open_acc', 'pub_rec',\n",
    "       'revol_bal', 'revol_util', 'total_acc', 'initial_list_status',\n",
    "       'last_credit_pull_d', 'collections_12_mths_ex_med', 'policy_code',\n",
    "       'application_type', 'acc_now_delinq', 'chargeoff_within_12_mths',\n",
    "       'delinq_amnt', 'pub_rec_bankruptcies', 'tax_liens']\n",
    "\n",
    "# The column that directly describes if a loan was paid off on time\n",
    "labels='loan_status'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[features_labels]\n",
    "\n",
    "# I can treat the problem as a binary classification one: 'Fully Paid' or 'Charged Off'\n",
    "df = df[(df['loan_status'] == \"Fully Paid\") | (df['loan_status'] == \"Charged Off\")]\n",
    "status_replace = {\"loan_status\" : {\"Fully Paid\": 1,\"Charged Off\": 0,}}\n",
    "df = df.replace(status_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345310, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that contain one true unique value\n",
    "orig_columns = df.columns\n",
    "drop_columns = []\n",
    "for col in orig_columns:\n",
    "    col_series = df[col].dropna().unique()\n",
    "    if len(col_series) == 1:\n",
    "        drop_columns.append(col)\n",
    "df.drop(drop_columns, axis=1,inplace=True)\n",
    "\n",
    "# Drop columns that offer very little variablity \n",
    "df.drop(['delinq_amnt','acc_now_delinq','collections_12_mths_ex_med',\n",
    "         'chargeoff_within_12_mths','tax_liens','application_type'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows containing missing values \n",
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1250804 entries, 0 to 2260697\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count    Dtype  \n",
      "---  ------                --------------    -----  \n",
      " 0   loan_amnt             1250804 non-null  float64\n",
      " 1   term                  1250804 non-null  object \n",
      " 2   int_rate              1250804 non-null  float64\n",
      " 3   installment           1250804 non-null  float64\n",
      " 4   emp_length            1250804 non-null  object \n",
      " 5   home_ownership        1250804 non-null  object \n",
      " 6   annual_inc            1250804 non-null  float64\n",
      " 7   verification_status   1250804 non-null  object \n",
      " 8   loan_status           1250804 non-null  int64  \n",
      " 9   purpose               1250804 non-null  object \n",
      " 10  title                 1250804 non-null  object \n",
      " 11  addr_state            1250804 non-null  object \n",
      " 12  dti                   1250804 non-null  float64\n",
      " 13  delinq_2yrs           1250804 non-null  float64\n",
      " 14  earliest_cr_line      1250804 non-null  object \n",
      " 15  inq_last_6mths        1250804 non-null  float64\n",
      " 16  open_acc              1250804 non-null  float64\n",
      " 17  pub_rec               1250804 non-null  float64\n",
      " 18  revol_bal             1250804 non-null  float64\n",
      " 19  revol_util            1250804 non-null  float64\n",
      " 20  total_acc             1250804 non-null  float64\n",
      " 21  initial_list_status   1250804 non-null  object \n",
      " 22  last_credit_pull_d    1250804 non-null  object \n",
      " 23  pub_rec_bankruptcies  1250804 non-null  float64\n",
      "dtypes: float64(13), int64(1), object(10)\n",
      "memory usage: 238.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         term emp_length home_ownership verification_status  \\\n",
      "0   36 months  10+ years       MORTGAGE        Not Verified   \n",
      "1   36 months  10+ years       MORTGAGE        Not Verified   \n",
      "4   60 months    3 years       MORTGAGE     Source Verified   \n",
      "5   36 months    4 years           RENT     Source Verified   \n",
      "6   36 months  10+ years       MORTGAGE        Not Verified   \n",
      "\n",
      "              purpose               title addr_state earliest_cr_line  \\\n",
      "0  debt_consolidation  Debt consolidation         PA         Aug-2003   \n",
      "1      small_business            Business         SD         Dec-1999   \n",
      "4      major_purchase      Major purchase         PA         Jun-1998   \n",
      "5  debt_consolidation  Debt consolidation         GA         Oct-1987   \n",
      "6  debt_consolidation  Debt consolidation         MN         Jun-1990   \n",
      "\n",
      "  initial_list_status last_credit_pull_d  \n",
      "0                   w           Mar-2019  \n",
      "1                   w           Mar-2019  \n",
      "4                   w           Mar-2018  \n",
      "5                   w           May-2017  \n",
      "6                   f           Mar-2019  \n",
      "Debt consolidation                622869\n",
      "Credit card refinancing           234263\n",
      "Home improvement                   69399\n",
      "Other                              61662\n",
      "Major purchase                     22590\n",
      "                                   ...  \n",
      "consolidatiom                          1\n",
      "Head Above Water Consolidation         1\n",
      "crf450                                 1\n",
      "CC Assist                              1\n",
      "Credit Cards Restructer                1\n",
      "Name: title, Length: 59051, dtype: int64\n",
      "debt_consolidation    728044\n",
      "credit_card           273873\n",
      "home_improvement       80284\n",
      "other                  71502\n",
      "major_purchase         27464\n",
      "small_business         14734\n",
      "medical                14068\n",
      "car                    13630\n",
      "moving                  8783\n",
      "vacation                8258\n",
      "house                   6764\n",
      "wedding                 2241\n",
      "renewable_energy         864\n",
      "educational              295\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exlore object column that contain text\n",
    "object_columns_df = df.select_dtypes(include=[\"object\"])\n",
    "print(object_columns_df.head())\n",
    "\n",
    "# Drop categorical columns that contain too many values\n",
    "\n",
    "df.drop('addr_state',axis=1,inplace=True)\n",
    "\n",
    "# Title and purpose columns are repeated information. Remove title column\n",
    "print(df[\"title\"].value_counts())\n",
    "print(df[\"purpose\"].value_counts())\n",
    "df.drop('title',axis=1,inplace=True)\n",
    "\n",
    "# Extract the year from time stamp features\n",
    "df['earliest_cr_year'] = df['earliest_cr_line'].apply(lambda date:int(date[-4:]))\n",
    "df = df.drop('earliest_cr_line',axis=1)\n",
    "df['last_credit_pull_year'] = df['last_credit_pull_d'].apply(lambda date:int(date[-4:]))\n",
    "df = df.drop('last_credit_pull_d',axis=1)\n",
    "\n",
    "# Convert the term feature into numeric data type\n",
    "df['term'] = df['term'].apply(lambda term: int(term[:3]))\n",
    "\n",
    "# Convert emp_length column to numeric type data\n",
    "df['emp_length'] = df['emp_length'].str.replace(r'\\+*\\syears*','').str.replace('< 1','0').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical and dummy variables\n",
    "# Convert home_ownership to dummy variables, but replace NONE and ANY with OTHER\n",
    "df['home_ownership']=df['home_ownership'].replace(['NONE', 'ANY'], 'OTHER')\n",
    "dummies = pd.get_dummies(df['home_ownership'],drop_first=True)\n",
    "df = df.drop('home_ownership',axis=1)\n",
    "df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "# Convert other categorical variables to dummy variables\n",
    "dummies = pd.get_dummies(df[['verification_status','initial_list_status','purpose' ]],drop_first=True)\n",
    "df = df.drop(['verification_status','initial_list_status','purpose'],axis=1)\n",
    "df = pd.concat([df,dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125080, 37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab a sample of the dataset\n",
    "df = df.sample(frac=0.1,random_state=101)\n",
    "\n",
    "features = df[df.columns.drop('loan_status')]\n",
    "target = df['loan_status']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[df.columns.drop(['loan_status'])]\n",
    "target = df['loan_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9833257240407329\n",
      "0.9292937597632163\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "\n",
    "# 10-fold cross validation\n",
    "predictions = cross_val_predict(lr, features, target, cv=10)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (df[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (df[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (df[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (df[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6915060444250353\n",
      "0.4052865247060758\n"
     ]
    }
   ],
   "source": [
    "# Account for imbalance in the classes\n",
    "lr = LogisticRegression(class_weight='balanced',max_iter=500)\n",
    "\n",
    "# 10-fold cross validation\n",
    "predictions = cross_val_predict(lr, features, target, cv=10)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (df[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (df[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (df[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (df[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp  / (tp + fn)\n",
    "fpr = fp  / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17548682930702503\n",
      "0.04526021540738305\n"
     ]
    }
   ],
   "source": [
    "# To improve FPR, impose a penalty of 10 for misclassifying a 0 and a penalty of 1 for misclassifying a 1\n",
    "penalty = {0: 10, 1: 1}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty,max_iter=500)\n",
    "predictions = cross_val_predict(lr, features, target, cv=10)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (df[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (df[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (df[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (df[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9810230859320722\n",
      "0.8816903724410097\n"
     ]
    }
   ],
   "source": [
    "# Account for the imbalance in the classes\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "\n",
    "# 10-fold cross validation\n",
    "predictions = cross_val_predict(rf, features, target, cv=10)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (df[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.`\n",
    "tp_filter = (predictions == 1) & (df[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (df[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (df[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(36,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(18, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 2s 20us/sample - loss: 0.4889\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4608\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4546\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4517\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4500\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4484\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4475\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4457\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4454\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4442\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4433\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4426\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4411\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4413\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4407\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4403\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4391\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4387\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4381\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4373\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4359\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4356\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4343\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4324\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4323\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4311\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - ETA: 0s - loss: 0.431 - 1s 8us/sample - loss: 0.4316\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4299\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4303\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4299\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4295\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4284\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4290\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4285\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4282\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4279\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4284\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4277\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4281\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4284\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4279\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4275\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4279\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4276\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4272\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4267\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4263\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4271\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4268\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4266\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4264\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4263\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4269\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4259\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4263\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4262\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4265\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4256\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4261\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4255\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4261\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4250\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4255\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4259\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4258\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4250\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4260\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4262\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4251\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4244\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4255\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4253\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4255\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4249\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4245\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4251\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4249\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4246\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4246\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4242\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4239\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4246\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4245\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4247\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4247\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4246\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4248\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4241\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4242\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4244\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4240\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4240\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4243\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4239\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4243\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4238\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4240\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4244\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4249\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4248\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4250\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4251\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4245\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4246\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4251\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4245\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4251\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4248\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4246\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4244\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4249\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4245\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4246\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4242\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4244\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4242\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4240\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4245\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4237\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4232\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4230\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4237\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4239\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4236\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4237\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4240\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4237\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4234\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4239\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4237\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4240\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4240\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4239\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4236\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4239\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4238\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4234\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4243\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4238\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4238\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4232\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4234\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4237\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4239\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4236\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4230\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4237\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4238\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4233\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4232\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4232\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4234\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4232\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4238\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4228\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4232\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4235\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4239\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4225\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4241\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4234\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4223\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4230\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4214\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4233\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4225\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4228\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4231\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4228\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4235\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4228\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4221\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4228\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4229\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4224\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4220\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4232\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4231\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4229\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4225\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4228\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4231\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4221\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4225\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4228\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4218\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4225\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4224\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4218\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4219\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4222\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4228\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4223\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4217\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4225\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4218\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4223\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4226\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4216\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4226\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4223\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4212\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4220\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4220\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4213\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4221\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4218\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4214\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4224\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4221\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4215\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4222\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4217\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4224\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4217\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4222\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4220\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4214\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4213\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4219\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4216\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4210\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4216\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4213\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4223\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4218\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4208\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4216\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4215\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4211\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4209\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4213\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 11us/sample - loss: 0.4212\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4219\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4214\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4210\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4231\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4228\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4228\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4222\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4229\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4226\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4224\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4226\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4228\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4216\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4221\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4232\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4219\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4223\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4228\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4217\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4223\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4223\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4217\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4227\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4226\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4213\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4220\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4218\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4223\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4219\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4223\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4225\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4210\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4216\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4223\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4212\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4224\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4221\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4219\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4219\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4214\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4221\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4223\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4220\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4216\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4220\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4216\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4221\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4222\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4222\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4215\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4223\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 11us/sample - loss: 0.4217\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4217\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4220\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4211\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4219\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4215\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4212\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4212\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4209\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4218\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4216\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4216\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4210\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4213\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4212\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4212\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4213\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4213\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4216\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4213\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4200\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4211\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4216\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4214\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4208\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4211\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4211\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4210\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4207\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4208\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4219\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4213\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4211\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4214\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4214\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4207\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4204\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4211\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4210\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4210\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4216\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4214\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4209\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4213\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4210\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4210\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4212\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4206\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4211\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4214\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4210\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4210\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4212\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4208\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4202\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4207\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4199\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4209\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4208\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4211\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4205\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4206\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4206\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4195\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4204\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4197\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4195\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4208\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4197\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4194\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4195\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4196\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4190\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4195\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4189\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4191\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4187\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4188\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4191\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4191\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4212\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4210\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4208\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4212\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4209\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4215\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4217\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4212\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4208\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4217\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4208\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4208\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4212\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4195\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203 0\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4209\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4191\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4187\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4195\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4196\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4196\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4188\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4194\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4189\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4188\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4190\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4189\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4193\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4187\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4187\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4190\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4189\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4183\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4191\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4185\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4218\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4214\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4213\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4213\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4210\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204 0\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4209\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4209\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4191\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4212\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4207\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4202\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4205\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4207\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4194\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4206\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4202\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4208\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4196\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4202\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4211\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4197\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4202\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4203\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4193\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4197\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4191\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4206\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4205\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4210\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203 0s\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4208\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4203\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4204\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4205\n",
      "Train on 112572 samples\n",
      "Epoch 1/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4199\n",
      "Epoch 2/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4204\n",
      "Epoch 3/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4196\n",
      "Epoch 4/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 5/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 6/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4206\n",
      "Epoch 7/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 8/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 9/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 10/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4196\n",
      "Epoch 11/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4197\n",
      "Epoch 12/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4201\n",
      "Epoch 13/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 14/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4203\n",
      "Epoch 15/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 16/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 17/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 18/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4190\n",
      "Epoch 19/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 20/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 21/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 22/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 23/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 24/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 25/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 26/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 27/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 28/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4191\n",
      "Epoch 29/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 30/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 31/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 32/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4190\n",
      "Epoch 33/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 34/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 35/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 36/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 37/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 38/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 39/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 40/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 41/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 42/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 43/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 44/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 45/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 46/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 47/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 48/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 49/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 50/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 51/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 52/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 53/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 54/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 55/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 56/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 57/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4198\n",
      "Epoch 58/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4198\n",
      "Epoch 59/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 60/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4195\n",
      "Epoch 61/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 62/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4187\n",
      "Epoch 63/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4201\n",
      "Epoch 64/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 65/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4193\n",
      "Epoch 66/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4190\n",
      "Epoch 67/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 68/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4207\n",
      "Epoch 69/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4197\n",
      "Epoch 70/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4202\n",
      "Epoch 71/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 72/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 73/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 74/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4200\n",
      "Epoch 75/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4199\n",
      "Epoch 76/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4194\n",
      "Epoch 77/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4189\n",
      "Epoch 78/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 79/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 80/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4192\n",
      "Epoch 81/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4190\n",
      "Epoch 82/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4200\n",
      "Epoch 83/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4195\n",
      "Epoch 84/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4189\n",
      "Epoch 85/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4187\n",
      "Epoch 87/100\n",
      "112572/112572 [==============================] - 1s 7us/sample - loss: 0.4196\n",
      "Epoch 88/100\n",
      "112572/112572 [==============================] - 1s 10us/sample - loss: 0.4192\n",
      "Epoch 89/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4191\n",
      "Epoch 90/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4199\n",
      "Epoch 91/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4193\n",
      "Epoch 92/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4189\n",
      "Epoch 93/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4189\n",
      "Epoch 94/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4182\n",
      "Epoch 95/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4192\n",
      "Epoch 96/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4195\n",
      "Epoch 97/100\n",
      "112572/112572 [==============================] - 1s 9us/sample - loss: 0.4194\n",
      "Epoch 98/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4194\n",
      "Epoch 99/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4194\n",
      "Epoch 100/100\n",
      "112572/112572 [==============================] - 1s 8us/sample - loss: 0.4192\n",
      "0.9778271830398793\n",
      "0.8443229466414536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=10, shuffle=True,random_state=1)\n",
    "fp=0\n",
    "tp=0\n",
    "fn=0\n",
    "tn=0\n",
    "\n",
    "for train_index,test_index in kf.split(features):\n",
    "    X_train,X_test = features.iloc[train_index].values, features.iloc[test_index].values\n",
    "    y_train,y_test = target.iloc[train_index].values, target.iloc[test_index].values\n",
    "    \n",
    "    # Data Transformation\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    \n",
    "    \n",
    "    model.fit(x=X_train, y=y_train, epochs=100,batch_size=250)\n",
    "    predictions = model.predict_classes(X_test)\n",
    "    results=confusion_matrix(y_test,predictions)\n",
    "    \n",
    "    # False positives.\n",
    "    fp += results[0][1]\n",
    "\n",
    "    # True positives.`\n",
    "    tp += results[1][1]\n",
    "\n",
    "    # False negatives.\n",
    "    fn += results[1][0]\n",
    "    \n",
    "    # True negatives\n",
    "    tn += results[0][0]\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Without accounting for imbalanced classes, the 3 models are good at identifying all the good loans (true positive rate), but also incorrectly identify most of bad loans (false positive rate). Neural networks model proves to be better (lowest FPR).\n",
    "\n",
    "When I account for imbalanced classes, the logistic model can lower the FPR to 4.7%, and thus lower the risk. Note that this comes at the expense of true positive rate (17%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
